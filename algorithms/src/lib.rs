use std::cmp::Ordering;
use std::hash::Hash;
use std::collections::{BinaryHeap, HashSet, VecDeque};

pub struct ActionSequence<T: UninformedState>(Option<T>);


impl<T: UninformedState> Iterator for ActionSequence<T> {
        type Item = T;

        fn next(&mut self) -> Option<Self::Item> {
            match self.0 {
                None => None,
                Some(ref state) => {
                    if let Some(&parent) = state.parent() {
                        std::mem::replace(&mut self.0, Some(parent))
                    } else {
                        std::mem::take(&mut self.0)
                    }
                }
            }
        }
}


pub enum DepthLimitedSearchResult<T> {
    Cutoff,
    Solution(T),
    Failure,
}


pub trait UninformedState: Hash + Eq + Clone + Copy {
    /// Representation of possible actions that agent can take.
    type Action: IntoIterator<Item=Self::Action>;
    /// Type of iterator that returns
    type Substates: Iterator<Item=Self>;

    /// Returns a reference to parent state of self.
    /// Returns Some(Self) if parent exists None if self was the initial state.
    fn parent(&self) -> Option<&Self>;

    /// Returns action that generated self.
    /// Returns None if self was the initial state that is was not generated by any action.
    fn produced_by(&self) -> Option<Self::Action>;

    /// Returns an iterator over actions.
    fn actions() -> Self::Action;

    /// Generates substates of self.
    fn substates(&self) -> Self::Substates;

    /// Checks if self is a final state.
    fn goal_test(&self) -> bool;

    /// Action cost function.
    /// Default implementation is a uniform cost function.
    fn cost_function(&self) -> i32;
    
    /// Generic iterative implementation of breath first search algorithm.
    fn breath_first_search(self) -> Option<ActionSequence<Self>> {
        if self.goal_test() { return Some(ActionSequence(Some(self))) }
        let mut visited = HashSet::<Self>::new();
        let mut queue = VecDeque::from([self]);
        while let Some(state) = queue.pop_front() {
            let substates = state.substates();
            visited.insert(state);
            for sub_state in substates {
                if !visited.contains(&sub_state) {
                    if sub_state.goal_test() { return Some(ActionSequence(Some(state))) }
                    queue.push_back(sub_state);
                }
            }
        }
        None
    }

    /// Generic iterative implementation of depth limited depth first search algorithm.
    fn depth_limited_search(self, limit: usize) -> DepthLimitedSearchResult<ActionSequence<Self>> {
        use DepthLimitedSearchResult::*;
        if self.goal_test() { return Solution(ActionSequence(Some(self))); }
        let mut visited = HashSet::<Self>::new();
        let mut depth = 0usize;
        let mut stack = VecDeque::from([self]);
        let mut cutoff_occurred = false;
        while let Some(state) = stack.pop_back() {
            visited.insert(state);
            let substates = state.substates();
            for sub_state in substates {
                if !visited.contains(&sub_state) {
                    if sub_state.goal_test() { return Solution(ActionSequence(Some(state))) }
                    /*
                     * If depth + 1 == limit then, substates would be leafs,
                     * but since we check if they are final before this condition,
                     * there is no reason to push them onto the stack.
                     */
                    if depth + 1 < limit {
                        cutoff_occurred = false;
                        stack.push_back(sub_state);
                    } else {
                        cutoff_occurred = true;
                    }
                }
            }
            depth += 1;
        }
        if cutoff_occurred { Cutoff } else { Failure }
    }

    /// Generic iterative implementation of iterative deepening search algorithm.
    /// It uses depth_limited_search with infinitely increasing limit value.
    fn iterative_deepening_search(self) -> Option<ActionSequence<Self>> {
        use DepthLimitedSearchResult::*;
        let mut depth_limit = 0;
        loop {
            let result = match self.depth_limited_search(depth_limit) {
                Cutoff => {
                    depth_limit += 1;
                    continue
                }
                Solution(action_seq) => { Some(action_seq) }
                Failure => { None }
            };
            return result;
        }
    }
}


struct StateOrdering<T: InformedState>(i32, T);


impl<T: InformedState> Eq for StateOrdering<T> {}


impl<T: InformedState> PartialEq<Self> for StateOrdering<T> {
    fn eq(&self, other: &Self) -> bool {
        self.0 == other.0
    }
}


impl<T: InformedState> PartialOrd<Self> for StateOrdering<T> {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.0.cmp(&other.0))
    }
}


impl<T: InformedState> std::cmp::Ord for StateOrdering<T> {
    fn cmp(&self, other: &Self) -> Ordering {
        self.0.cmp(&other.0)
    }
}


pub trait InformedState : UninformedState {
    fn heuristic(&self) -> i32;

    fn a_star_search(self) -> Option<ActionSequence<Self>> {
        if self.goal_test() { return Some(ActionSequence(Some(self))) }
        let mut priority_queue = BinaryHeap::<StateOrdering<Self>>::from(
            [StateOrdering(self.cost_function() + self.heuristic(), self)]
        );

        None
    }
}


#[cfg(test)]
mod tests {
    #[test]
    fn it_works() {
        let result = 2 + 2;
        assert_eq!(result, 4);
    }
}
